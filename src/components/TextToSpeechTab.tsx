import { useState, useRef, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Play, Loader2 } from "lucide-react";
import { toast } from "sonner";
import { supabase } from "@/integrations/supabase/client";
import { useGlobalAudio } from "@/hooks/useGlobalAudio";
import WaveformAnimation from "@/components/ui/WaveformAnimation";

const SUPABASE_URL = import.meta.env.VITE_SUPABASE_URL;
const SUPABASE_ANON_KEY = import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY;

// Voice configurations for each case
const voiceConfigs: Record<string, { voice: string; text: string }> = {
  case1: {
    voice: "cixingnansheng",
    text: "é˜¶è·ƒæ˜Ÿè¾°è¿‘æ—¥æ­£å¼å‘å¸ƒæ–°ä¸€ä»£åŸºç¡€å¤§æ¨¡å‹Step 3ï¼Œå…¼é¡¾æ™ºèƒ½ä¸æ•ˆç‡ï¼Œé¢å‘æ¨ç†æ—¶ä»£æ‰“é€ æœ€é€‚åˆåº”ç”¨çš„æ¨¡å‹ã€‚Step 3å°†é¢å‘å…¨çƒä¼ä¸šå’Œå¼€å‘è€…å¼€æºï¼Œä¸ºå¼€æºä¸–ç•Œè´¡çŒ®æœ€å¼ºå¤šæ¨¡æ€æ¨ç†æ¨¡å‹ã€‚",
  },
  case2: {
    voice: "tianmeinvsheng", 
    text: "æ·±å¤œï¼Œè€å®…çš„é’Ÿæ•²å“åäºŒä¸‹ã€‚å¥¹æ¨å¼€å°˜å°çš„é˜æ¥¼é—¨ï¼Œå‘ç°ä¸€å°æ³›é»„çš„ä¿¡â€”â€”æ”¶ä»¶äººç«Ÿæ˜¯è‡ªå·±çš„åå­—ï¼Œè½æ¬¾æ—¥æœŸå´æ˜¯æ˜å¤©ã€‚ä¿¡ä¸Šåªæœ‰ä¸€å¥è¯ï¼šä¸è¦å›å¤´ã€‚å¥¹çš„å¿ƒè·³éª¤ç„¶åŠ é€Ÿï¼Œèº«åä¼ æ¥è½»å¾®çš„è„šæ­¥å£°ã€‚å¥¹å±ä½å‘¼å¸ï¼Œç¼“ç¼“è½¬èº«ï¼Œå´åªçœ‹è§ç©ºè¡è¡çš„èµ°å»Šå’Œä¸€é¢è½æ»¡ç°å°˜çš„é•œå­ã€‚é•œä¸­çš„è‡ªå·±æ­£å¾®ç¬‘ç€ï¼Œä½†å¥¹æ­¤åˆ»åˆ†æ˜æ²¡æœ‰ç¬‘ã€‚",
  },
};

const dialogueLines = [
  { speaker: "å®¢æœå°ç¾", text: "æ‚¨å¥½ï¼Œæ¬¢è¿è‡´ç”µæ™ºèƒ½å®¢æœä¸­å¿ƒï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ", voice: "tianmeinvsheng" },
  { speaker: "å®¢æˆ·å…ˆç”Ÿ", text: "ä½ å¥½ï¼Œæˆ‘æ˜¨å¤©ä¸‹çš„è®¢å•æ˜¾ç¤ºå·²å‘è´§ï¼Œä½†ç‰©æµä¿¡æ¯ä¸€ç›´æ²¡æ›´æ–°ã€‚", voice: "cixingnansheng" },
  { speaker: "å®¢æœå°ç¾", text: "å¥½çš„ï¼Œè¯·æ‚¨æä¾›ä¸€ä¸‹è®¢å•å·ï¼Œæˆ‘å¸®æ‚¨æŸ¥è¯¢ã€‚", voice: "tianmeinvsheng" },
  { speaker: "å®¢æˆ·å…ˆç”Ÿ", text: "è®¢å•å·æ˜¯202412250001ã€‚", voice: "cixingnansheng" },
  { speaker: "å®¢æœå°ç¾", text: "å·²æŸ¥åˆ°ï¼Œæ‚¨çš„åŒ…è£¹ç›®å‰åœ¨è½¬è¿ä¸­ï¼Œé¢„è®¡æ˜å¤©é€è¾¾ï¼Œè¯·æ‚¨è€å¿ƒç­‰å¾…ã€‚", voice: "tianmeinvsheng" },
  { speaker: "å®¢æˆ·å…ˆç”Ÿ", text: "å¥½çš„ï¼Œè°¢è°¢ï¼", voice: "cixingnansheng" },
];

const cases = [
  {
    id: "case1",
    label: "æ–°é—»æ’­æŠ¥",
    description: "Step 3æ¨¡å‹å‘å¸ƒ",
    icon: "ğŸ“°",
    gradient: "from-blue-400 to-cyan-400",
    text: voiceConfigs.case1.text,
    isDialogue: false,
  },
  {
    id: "case2",
    label: "æœ‰å£°è¯»ç‰©",
    description: "æ‚¬ç–‘æ•…äº‹",
    icon: "ğŸ“–",
    gradient: "from-purple-400 to-pink-400",
    text: voiceConfigs.case2.text,
    isDialogue: false,
  },
  {
    id: "case3",
    label: "å®¢æœåŠ©æ‰‹",
    description: "æ™ºèƒ½å®¢æœå¯¹è¯",
    icon: "ğŸ§",
    gradient: "from-green-400 to-emerald-400",
    text: dialogueLines.map(line => `${line.speaker}ï¼š${line.text}`).join("\n"),
    isDialogue: true,
  },
];

// Storage file paths for pre-generated audio
const storageFiles: Record<string, string> = {
  case1: "tts/case1.mp3",
  case2: "tts/case2.mp3",
  "dialogue-0": "tts/dialogue-0.mp3",
  "dialogue-1": "tts/dialogue-1.mp3",
  "dialogue-2": "tts/dialogue-2.mp3",
  "dialogue-3": "tts/dialogue-3.mp3",
  "dialogue-4": "tts/dialogue-4.mp3",
  "dialogue-5": "tts/dialogue-5.mp3",
};

const TextToSpeechTab = () => {
  const [activeCase, setActiveCase] = useState("case1");
  const [isPlaying, setIsPlaying] = useState(false);
  const [isGenerating, setIsGenerating] = useState(false);
  const [cachedAudioUrls, setCachedAudioUrls] = useState<Record<string, string>>({});
  const [storageUrls, setStorageUrls] = useState<Record<string, string>>({});
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const dialogueIndexRef = useRef(0);
  const currentCase = cases.find((c) => c.id === activeCase) || cases[0];
  const { playAudio, stopGlobalAudio } = useGlobalAudio();

  // Check storage for pre-generated audio on mount
  useEffect(() => {
    const checkStorageFiles = async () => {
      const urls: Record<string, string> = {};
      
      for (const [caseId, filePath] of Object.entries(storageFiles)) {
        const { data } = supabase.storage.from("audio").getPublicUrl(filePath);
        try {
          // Quick check if file exists with valid content
          const response = await fetch(data.publicUrl, { 
            method: "HEAD",
          });
          if (response.ok) {
            urls[caseId] = data.publicUrl;
          }
        } catch {
          // File doesn't exist
        }
      }
      
      setStorageUrls(urls);
    };
    
    checkStorageFiles();
  }, []);

  // Generate single audio on demand
  const generateSingleAudio = async (text: string, voice: string): Promise<string | null> => {
    try {
      const response = await fetch(`${SUPABASE_URL}/functions/v1/step-tts`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          apikey: SUPABASE_ANON_KEY,
          Authorization: `Bearer ${SUPABASE_ANON_KEY}`,
        },
        body: JSON.stringify({ text, voice }),
      });

      if (!response.ok) {
        throw new Error("Failed to generate audio");
      }

      const audioBlob = await response.blob();
      return URL.createObjectURL(audioBlob);
    } catch (error) {
      console.error("Error generating audio:", error);
      return null;
    }
  };

  // Play single case audio
  const playSingleAudio = async () => {
    const config = voiceConfigs[activeCase];
    if (!config) return;

    // Priority: 1. Memory cache, 2. Storage, 3. Generate
    let audioUrl = cachedAudioUrls[activeCase] || storageUrls[activeCase];
    
    if (!audioUrl) {
      setIsGenerating(true);
      toast.info("æ­£åœ¨ç”ŸæˆéŸ³é¢‘...");
      audioUrl = await generateSingleAudio(config.text, config.voice);
      setIsGenerating(false);
      
      if (!audioUrl) {
        toast.error("éŸ³é¢‘ç”Ÿæˆå¤±è´¥");
        return;
      }
      
      // Cache the URL
      setCachedAudioUrls(prev => ({ ...prev, [activeCase]: audioUrl! }));
    }

    const audio = new Audio(audioUrl);
    audioRef.current = audio;
    playAudio(audio, () => {
      setIsPlaying(false);
      audioRef.current = null;
    });

    audio.onended = () => {
      setIsPlaying(false);
      audioRef.current = null;
    };

    audio.onerror = () => {
      setIsPlaying(false);
      audioRef.current = null;
      toast.error("éŸ³é¢‘æ’­æ”¾å¤±è´¥");
    };

    audio.play();
    setIsPlaying(true);
  };

  // Play dialogue sequentially
  const playDialogue = async () => {
    dialogueIndexRef.current = 0;
    setIsPlaying(true);
    setIsGenerating(true);
    toast.info("æ­£åœ¨ç”Ÿæˆå¯¹è¯éŸ³é¢‘...");

    const playNext = async () => {
      if (dialogueIndexRef.current >= dialogueLines.length) {
        setIsPlaying(false);
        audioRef.current = null;
        return;
      }

      const line = dialogueLines[dialogueIndexRef.current];
      const cacheKey = `dialogue-${dialogueIndexRef.current}`;
      
      // Priority: 1. Memory cache, 2. Storage, 3. Generate
      let audioUrl = cachedAudioUrls[cacheKey] || storageUrls[cacheKey];
      if (!audioUrl) {
        audioUrl = await generateSingleAudio(line.text, line.voice);
        if (!audioUrl) {
          toast.error("å¯¹è¯éŸ³é¢‘ç”Ÿæˆå¤±è´¥");
          setIsPlaying(false);
          setIsGenerating(false);
          return;
        }
        setCachedAudioUrls(prev => ({ ...prev, [cacheKey]: audioUrl! }));
      }
      
      setIsGenerating(false);

      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      playAudio(audio, () => {
        setIsPlaying(false);
        audioRef.current = null;
      });

      audio.onended = async () => {
        dialogueIndexRef.current += 1;
        if (dialogueIndexRef.current < dialogueLines.length) {
          setIsGenerating(true);
        }
        await playNext();
      };

      audio.onerror = () => {
        setIsPlaying(false);
        audioRef.current = null;
        toast.error("éŸ³é¢‘æ’­æ”¾å¤±è´¥");
      };

      audio.play();
    };

    await playNext();
  };

  const handlePlayPause = async () => {
    if (audioRef.current && isPlaying) {
      audioRef.current.pause();
      setIsPlaying(false);
      return;
    }

    if (audioRef.current && !isPlaying) {
      audioRef.current.play();
      setIsPlaying(true);
      return;
    }

    if (currentCase.isDialogue) {
      await playDialogue();
      return;
    }

    await playSingleAudio();
  };

  const handleCaseChange = (caseId: string) => {
    stopGlobalAudio();
    audioRef.current = null;
    setIsPlaying(false);
    dialogueIndexRef.current = 0;
    setActiveCase(caseId);
  };

  return (
    <div className="animate-fade-in">
      {/* Text Display Area */}
      <div className="bg-card border border-border rounded-lg p-6 mb-4 min-h-[160px] shadow-soft">
        <pre className="text-foreground font-mono text-sm whitespace-pre-wrap leading-relaxed">
          {currentCase.text}
        </pre>
      </div>

      {/* Case Selector */}
      <div className="flex flex-wrap items-center gap-3 mb-6">
        {cases.map((caseItem) => (
          <button
            key={caseItem.id}
            onClick={() => handleCaseChange(caseItem.id)}
            className={`
              flex items-center gap-2.5 px-4 py-2.5 rounded-lg border transition-all duration-200
              ${activeCase === caseItem.id 
                ? 'bg-primary/10 border-primary/50 shadow-md shadow-primary/10' 
                : 'bg-card/50 border-border/50 hover:bg-card hover:border-border'
              }
            `}
          >
            <span className={`
              w-6 h-6 rounded-full bg-gradient-to-br ${caseItem.gradient} 
              flex items-center justify-center text-xs shadow-sm
            `}>
              {caseItem.icon}
            </span>
            <span className="text-sm font-medium text-foreground">{caseItem.label}</span>
            <span className="text-muted-foreground/50">|</span>
            <span className="text-sm text-muted-foreground">{caseItem.description}</span>
          </button>
        ))}
      </div>

      {/* Description and Play */}
      <div className="flex items-center justify-between">
        <p className="text-sm text-muted-foreground">
          <span className="text-foreground font-medium">@Step-tts-2</span>{" "}
          ç”Ÿæˆæ•ˆå…·æœ‰äººæ„Ÿã€æ‹¥æœ‰ä¸°å¯Œæƒ…ç»ªã€é£æ ¼çš„è¯­éŸ³
        </p>
        <Button 
          className="gap-2.5 px-6 py-2.5 h-auto text-base font-semibold bg-primary hover:bg-primary/90 text-primary-foreground shadow-lg shadow-primary/25 hover:shadow-xl hover:shadow-primary/30 transition-all duration-300"
          onClick={handlePlayPause}
          disabled={isGenerating}
        >
          {isGenerating ? (
            <Loader2 className="h-4 w-4 animate-spin" />
          ) : isPlaying ? (
            <WaveformAnimation isPlaying={true} variant="small" barCount={4} className="text-primary-foreground [&>div]:bg-primary-foreground" />
          ) : (
            <Play className="h-4 w-4" />
          )}
          {isGenerating ? "ç”Ÿæˆä¸­..." : isPlaying ? "æ’­æ”¾ä¸­" : "æ’­æ”¾"}
        </Button>
      </div>
    </div>
  );
};

export default TextToSpeechTab;
