import { useState, useRef, useEffect, useCallback } from "react";
import { createPortal } from "react-dom";
import { Button } from "@/components/ui/button";
import { Play, Pause, Upload, Mic, RefreshCw, Trash2, X, Loader2, ChevronLeft, ChevronRight, Pencil } from "lucide-react";
import { toast } from "sonner";

import { Headphones, MessageSquare, Megaphone, GraduationCap, Radio, Newspaper } from "lucide-react";

// Sample texts for recording (~50 characters each, 10-30s reading time)
const sampleTexts = [
  "åœ¨è¿™ä¸ªå¿«é€Ÿå‘å±•çš„æ—¶ä»£ï¼Œç§‘æŠ€æ”¹å˜äº†æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿæ›´åŠ ä¾¿æ·åœ°ä¸ä¸–ç•Œå„åœ°çš„äººä»¬è¿›è¡Œäº¤æµå’Œäº’åŠ¨ã€‚",
  "æ˜¥å¤©çš„é˜³å…‰æ¸©æš–è€Œæ˜åªšï¼Œä¸‡ç‰©å¤è‹çš„å­£èŠ‚é‡Œï¼ŒèŠ±æœµç«ç›¸ç»½æ”¾ï¼Œé¸Ÿå„¿åœ¨æå¤´æ­Œå”±ï¼Œä¸€åˆ‡éƒ½æ˜¾å¾—ç”Ÿæœºå‹ƒå‹ƒã€‚",
  "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨æ·±åˆ»åœ°æ”¹å˜ç€å„è¡Œå„ä¸šï¼Œä»åŒ»ç–—è¯Šæ–­åˆ°è‡ªåŠ¨é©¾é©¶ï¼Œå®ƒçš„åº”ç”¨èŒƒå›´è¶Šæ¥è¶Šå¹¿æ³›ï¼Œå½±å“ç€æ¯ä¸ªäººçš„æ—¥å¸¸ç”Ÿæ´»ã€‚",
  "å¤œæ™šçš„åŸå¸‚ç¯ç«è¾‰ç…Œï¼Œé«˜æ¥¼å¤§å¦çš„çª—æˆ·é‡Œé€å‡ºæ¸©æš–çš„å…‰èŠ’ï¼Œè¡—é“ä¸Šè½¦æ°´é©¬é¾™ï¼Œäººä»¬åŒ†åŒ†å¿™å¿™åœ°èµ¶å¾€å„è‡ªçš„ç›®çš„åœ°ã€‚",
  "éŸ³ä¹æ˜¯ä¸€ç§æ— å›½ç•Œçš„è¯­è¨€ï¼Œå®ƒèƒ½å¤Ÿè·¨è¶Šæ–‡åŒ–å’Œåœ°åŸŸçš„é™åˆ¶ï¼Œè§¦åŠ¨æ¯ä¸ªäººå¿ƒä¸­æœ€æŸ”è½¯çš„éƒ¨åˆ†ï¼Œå¸¦æ¥æ— å°½çš„æ„ŸåŠ¨ä¸å…±é¸£ã€‚",
];

// Preset scenarios for quick generation
const presetScenarios = [
  { id: "news", icon: Newspaper, title: "æ–°é—»æ’­æŠ¥", subtitle: "Step 3æ¨¡å‹å‘å¸ƒ", color: "text-emerald-500", bgColor: "bg-emerald-50", text: "æœ€æ–°æ¶ˆæ¯ï¼ŒStep 3è¯­éŸ³æ¨¡å‹æ­£å¼å‘å¸ƒï¼Œæ”¯æŒå¤šç§æƒ…æ„Ÿé£æ ¼çš„è‡ªç„¶è¯­éŸ³åˆæˆï¼Œä¸ºç”¨æˆ·å¸¦æ¥æ›´åŠ çœŸå®çš„è¯­éŸ³ä½“éªŒã€‚" },
  { id: "audiobook", icon: Headphones, title: "æœ‰å£°è¯»ç‰©", subtitle: "æ‚¬ç–‘æ•…äº‹", color: "text-purple-500", bgColor: "bg-purple-50", text: "é‚£ä¸ªé›¨å¤œï¼Œä»–ç‹¬è‡ªèµ°åœ¨ç©ºæ— ä¸€äººçš„è¡—é“ä¸Šã€‚çªç„¶ï¼Œä¸€é“é—ªç”µåˆ’ç ´å¤œç©ºï¼Œä»–çœ‹åˆ°äº†ä¸€ä¸ªç¥ç§˜çš„èº«å½±ç«™åœ¨è¡—è§’ã€‚" },
  { id: "service", icon: MessageSquare, title: "å®¢æœåŠ©æ‰‹", subtitle: "æ™ºèƒ½å®¢æœå¯¹è¯", color: "text-orange-500", bgColor: "bg-orange-50", text: "æ‚¨å¥½ï¼Œæ¬¢è¿è‡´ç”µå®¢æˆ·æœåŠ¡ä¸­å¿ƒã€‚æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ" },
  { id: "ad", icon: Megaphone, title: "å¹¿å‘Šé…éŸ³", subtitle: "å“ç‰Œå®£ä¼ ç‰‡", color: "text-pink-500", bgColor: "bg-pink-50", text: "æ¢ç´¢æ— é™å¯èƒ½ï¼Œåˆ›é€ ç²¾å½©æœªæ¥ã€‚æˆ‘ä»¬ç”¨ç§‘æŠ€æ”¹å˜ç”Ÿæ´»ï¼Œç”¨åˆ›æ–°å®šä¹‰æ˜å¤©ã€‚" },
  { id: "education", icon: GraduationCap, title: "æ•™è‚²æœ—è¯»", subtitle: "å¤è¯—è¯èµæ", color: "text-blue-500", bgColor: "bg-blue-50", text: "åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚è¿™é¦–è¯—è¡¨è¾¾äº†è¯—äººå¯¹æ•…ä¹¡çš„æ·±æ·±æ€å¿µä¹‹æƒ…ã€‚" },
  { id: "radio", icon: Radio, title: "æƒ…æ„Ÿç”µå°", subtitle: "æ·±å¤œæ²»æ„ˆ", color: "text-red-500", bgColor: "bg-red-50", text: "åœ¨è¿™ä¸ªå®‰é™çš„å¤œæ™šï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ”¾æ…¢è„šæ­¥ï¼Œè†å¬å†…å¿ƒçš„å£°éŸ³ã€‚æ„¿ä½ ä»Šå¤œå¥½æ¢¦ï¼Œæ˜å¤©ä¾ç„¶å……æ»¡å¸Œæœ›ã€‚" },
];

const emotionTags = ["é«˜å…´", "æ„¤æ€’", "æ‚²ä¼¤", "å¹½é»˜", "å›°æƒ‘", "åŒæ¶", "å…±æƒ…", "å°´å°¬", "ææƒ§", "æƒŠè®¶", "å…´å¥‹", "æ²®ä¸§", "å†·æ¼ ", "é’¦ä½©"];
const styleTags = [
  "ä¸¥è‚ƒ", "å‚²æ…¢", "å„¿ç«¥", "å•çº¯", "å¤¸å¼ ", "å°‘å¥³", "å¾¡å§", "æœ—è¯µ",
  "ç”œç¾", "ç©ºçµ", "è±ªçˆ½", "æ’’å¨‡", "æ¸©æš–", "å®³ç¾", "å®‰æ…°", "æƒå¨",
  "é—²èŠ", "ç”µå°", "æ·±æƒ…", "æ¸©æŸ”", "ç£æ€§", "ä¸­è€å¹´", "æ‚„æ‚„è¯",
  "æ°”æ³¡éŸ³", "è®²æ•…äº‹", "ç»˜å£°ç»˜è‰²", "èŠ‚ç›®ä¸»æŒ", "æ–°é—»æ’­æŠ¥", "å¹¿å‘Šè¥é”€",
  "å¨±ä¹å…«å¦", "å¼å«", "å°å£°", "å¤§å£°", "ä½æ²‰", "é«˜äº¢"
];
const speedTags = ["å¿«é€Ÿ", "æ…¢é€Ÿ", "æ›´å¿«", "æ›´æ…¢"];

export interface SentenceSegment {
  id: number;
  text: string;
  isEdited: boolean;
  versions: { url: string; tags: string[] }[];
  currentVersionIndex: number;
}

interface VoiceEditTabProps {
  onAudioGenerated?: (audioUrl: string, title: string) => void;
  onAudioDeleted?: () => void;
  onSentencesChange?: (sentences: SentenceSegment[]) => void;
  onGeneratingChange?: (isGenerating: boolean, title?: string) => void;
}

const VoiceEditTab = ({ onAudioGenerated, onAudioDeleted, onSentencesChange, onGeneratingChange }: VoiceEditTabProps) => {
  // Upload/Record state
  const [audioSource, setAudioSource] = useState<"none" | "upload" | "record">("none");
  const [originalAudioBlob, setOriginalAudioBlob] = useState<Blob | null>(null);
  const [originalAudioUrl, setOriginalAudioUrl] = useState<string | null>(null);
  const [originalFileName, setOriginalFileName] = useState<string>("");
  
  // Recording state
  const [sampleText, setSampleText] = useState(sampleTexts[0]);
  const [isRecording, setIsRecording] = useState(false);
  const [countdown, setCountdown] = useState(30);
  
  // Sentence segments state
  const [sentences, setSentences] = useState<SentenceSegment[]>([]);
  const [editingSentenceId, setEditingSentenceId] = useState<number | null>(null);
  
  // Edit state
  const [showModal, setShowModal] = useState(false);
  const [selectedTags, setSelectedTags] = useState<string[]>([]);
  const [isGenerating, setIsGenerating] = useState(false);
  const [isGeneratingPreset, setIsGeneratingPreset] = useState<string | null>(null);
  
  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const countdownIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const fileInputRef = useRef<HTMLInputElement | null>(null);

  // Notify parent when sentences change
  useEffect(() => {
    onSentencesChange?.(sentences);
  }, [sentences, onSentencesChange]);

  // Split text into sentences
  const splitIntoSentences = (text: string): string[] => {
    return text
      .split(/[ã€‚ï¼ï¼Ÿï¼Œï¼›]/)
      .filter(s => s.trim().length > 0)
      .map(s => s.trim());
  };

  // Generate random sample text
  const generateRandomText = () => {
    const currentIndex = sampleTexts.indexOf(sampleText);
    let newIndex = Math.floor(Math.random() * sampleTexts.length);
    while (newIndex === currentIndex && sampleTexts.length > 1) {
      newIndex = Math.floor(Math.random() * sampleTexts.length);
    }
    setSampleText(sampleTexts[newIndex]);
  };

  // Handle preset scenario click
  const handlePresetClick = async (scenario: typeof presetScenarios[0]) => {
    if (isGeneratingPreset) return;
    
    setIsGeneratingPreset(scenario.id);
    
    // Immediately show next step with sentences
    const sentenceTexts = splitIntoSentences(scenario.text);
    const newSentences: SentenceSegment[] = sentenceTexts.map((text, index) => ({
      id: index,
      text,
      isEdited: false,
      versions: [],
      currentVersionIndex: -1,
    }));
    setSentences(newSentences);
    setAudioSource("record");
    
    // Notify parent that we're generating
    onGeneratingChange?.(true, `${scenario.title} - ${scenario.subtitle}`);
    
    try {
      const response = await fetch(
        `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/step-tts`,
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY,
            Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
          },
          body: JSON.stringify({
            text: scenario.text,
            voice: "tianmeinvsheng",
          }),
        }
      );

      if (!response.ok) {
        throw new Error("Failed to generate audio");
      }

      const audioBlob = await response.blob();
      const url = URL.createObjectURL(audioBlob);
      
      setOriginalAudioBlob(audioBlob);
      setOriginalAudioUrl(url);
      setOriginalFileName(`${scenario.title}_${scenario.subtitle}.wav`);
      
      onAudioGenerated?.(url, `${scenario.title} - ${scenario.subtitle}`);
      toast.success(`${scenario.title}éŸ³é¢‘ç”ŸæˆæˆåŠŸ`);
    } catch (error) {
      console.error("Error generating preset audio:", error);
      toast.error("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•");
      // Reset state on error
      setSentences([]);
      setAudioSource("none");
    } finally {
      setIsGeneratingPreset(null);
      onGeneratingChange?.(false);
    }
  };

  // Handle file upload
  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith("audio/")) {
      toast.error("è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆmp3, wavç­‰ï¼‰");
      return;
    }

    if (file.size > 10 * 1024 * 1024) {
      toast.error("æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡10MB");
      return;
    }

    const url = URL.createObjectURL(file);
    setOriginalAudioBlob(file);
    setOriginalAudioUrl(url);
    setOriginalFileName(file.name);
    setAudioSource("upload");
    setSentences([]);
    toast.success("éŸ³é¢‘ä¸Šä¼ æˆåŠŸ");
  };

  // Start recording
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/wav" });
        const url = URL.createObjectURL(audioBlob);
        setOriginalAudioBlob(audioBlob);
        setOriginalAudioUrl(url);
        setOriginalFileName(`å½•åˆ¶_${Date.now()}.wav`);
        setAudioSource("record");
        stream.getTracks().forEach(track => track.stop());
        
        // Split the sample text into sentences
        const sentenceTexts = splitIntoSentences(sampleText);
        const newSentences: SentenceSegment[] = sentenceTexts.map((text, index) => ({
          id: index,
          text,
          isEdited: false,
          versions: [],
          currentVersionIndex: -1,
        }));
        setSentences(newSentences);
        
        // Notify parent with the first audio
        onAudioGenerated?.(url, "å½•åˆ¶éŸ³é¢‘");
      };

      mediaRecorder.start();
      setIsRecording(true);
      setCountdown(30);

      countdownIntervalRef.current = setInterval(() => {
        setCountdown((prev) => prev - 1);
      }, 1000);

      toast.success("å¼€å§‹å½•åˆ¶ï¼Œè¯·æœ—è¯»æ–‡æœ¬");
    } catch (error) {
      console.error("Error accessing microphone:", error);
      toast.error("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®");
    }
  };

  // Stop recording
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      if (countdownIntervalRef.current) {
        clearInterval(countdownIntervalRef.current);
        countdownIntervalRef.current = null;
      }
      toast.success("å½•åˆ¶å®Œæˆ");
    }
  }, [isRecording]);

  // Auto stop when countdown reaches 0
  useEffect(() => {
    if (countdown === 0 && isRecording) {
      stopRecording();
    }
  }, [countdown, isRecording, stopRecording]);

  // Delete audio
  const deleteAudio = () => {
    if (originalAudioUrl) {
      URL.revokeObjectURL(originalAudioUrl);
    }
    sentences.forEach(sentence => {
      sentence.versions.forEach(v => URL.revokeObjectURL(v.url));
    });
    setOriginalAudioBlob(null);
    setOriginalAudioUrl(null);
    setOriginalFileName("");
    setAudioSource("none");
    setSentences([]);
    onAudioDeleted?.();
  };

  // Open edit modal for a sentence (called from parent)
  const openEditModal = (sentenceId: number) => {
    setEditingSentenceId(sentenceId);
    setShowModal(true);
  };

  // Expose openEditModal to parent
  useEffect(() => {
    (window as any).__voiceEditOpenModal = openEditModal;
    return () => {
      delete (window as any).__voiceEditOpenModal;
    };
  }, []);

  // Toggle tag selection
  const toggleTag = (tag: string) => {
    setSelectedTags(prev => 
      prev.includes(tag) 
        ? prev.filter(t => t !== tag) 
        : [...prev, tag]
    );
  };

  // Handle edit confirm for a sentence
  const handleConfirm = async () => {
    if (selectedTags.length === 0) {
      toast.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç¼–è¾‘å‚æ•°");
      return;
    }
    
    if (editingSentenceId === null) return;
    
    const sentence = sentences.find(s => s.id === editingSentenceId);
    if (!sentence) return;
    
    setShowModal(false);
    setIsGenerating(true);
    const currentTags = [...selectedTags];
    setSelectedTags([]);
    
    try {
      const response = await fetch(
        `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/step-tts`,
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            apikey: import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY,
            Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`,
          },
          body: JSON.stringify({
            text: sentence.text,
            voice: "tianmeinvsheng",
          }),
        }
      );

      if (!response.ok) {
        throw new Error("Failed to generate edited audio");
      }

      const audioBlob = await response.blob();
      const url = URL.createObjectURL(audioBlob);
      
      setSentences(prev => prev.map(s => {
        if (s.id === editingSentenceId) {
          const newVersions = [...s.versions, { url, tags: currentTags }];
          return {
            ...s,
            isEdited: true,
            versions: newVersions,
            currentVersionIndex: newVersions.length - 1,
          };
        }
        return s;
      }));
      
      onAudioGenerated?.(url, `å¥å­${editingSentenceId + 1}_ç¼–è¾‘ç‰ˆæœ¬`);
      toast.success(`å¥å­ç¼–è¾‘æˆåŠŸï¼Œå·²åº”ç”¨ ${currentTags.length} ä¸ªé£æ ¼æ ‡ç­¾`);
    } catch (error) {
      console.error("Error generating edited audio:", error);
      toast.error("éŸ³é¢‘ç¼–è¾‘å¤±è´¥ï¼Œè¯·é‡è¯•");
    } finally {
      setIsGenerating(false);
      setEditingSentenceId(null);
    }
  };

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (countdownIntervalRef.current) {
        clearInterval(countdownIntervalRef.current);
      }
      if (originalAudioUrl) {
        URL.revokeObjectURL(originalAudioUrl);
      }
      sentences.forEach(sentence => {
        sentence.versions.forEach(v => URL.revokeObjectURL(v.url));
      });
    };
  }, []);

  return (
    <div className="animate-fade-in space-y-6">
      {/* Hidden file input */}
      <input
        ref={fileInputRef}
        type="file"
        accept="audio/*"
        className="hidden"
        onChange={handleFileUpload}
      />

      {/* Initial State: Upload or Record */}
      {audioSource === "none" && !isRecording && (
        <div className="space-y-6">
          {/* Upload/Record Section */}
          <div className="bg-primary/5 border border-primary/20 rounded-lg p-8">
            <div className="flex flex-col items-center gap-4">
              <div className="relative">
                <svg 
                  width="80" 
                  height="60" 
                  viewBox="0 0 80 60" 
                  fill="none"
                  className="text-primary"
                >
                  <path 
                    d="M5 30 L10 30 L15 20 L20 40 L25 15 L30 45 L35 10 L40 50 L45 5 L50 55 L55 20 L60 35 L65 25 L70 30 L75 30" 
                    stroke="currentColor" 
                    strokeWidth="2.5" 
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    fill="none"
                  />
                </svg>
                <div className="absolute -top-2 -right-4">
                  <svg 
                    width="24" 
                    height="24" 
                    viewBox="0 0 24 24" 
                    fill="none"
                    className="text-primary"
                  >
                    <path 
                      d="M17 3a2.85 2.85 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z" 
                      stroke="currentColor" 
                      strokeWidth="2" 
                      strokeLinecap="round" 
                      strokeLinejoin="round"
                      fill="hsl(var(--primary) / 0.1)"
                    />
                  </svg>
                </div>
              </div>
              <div className="text-center">
                <p className="text-sm text-muted-foreground">
                  è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶ï¼Œå¯ç›´æ¥å½•åˆ¶
                </p>
                <p className="text-xs text-muted-foreground mt-1">
                  æ”¯æŒmp3/wavæ ¼å¼ï¼Œé™åˆ¶æ—¶é•¿10-30S
                </p>
              </div>
              <div className="flex items-center gap-3 mt-2">
                <Button
                  variant="outline"
                  onClick={() => fileInputRef.current?.click()}
                  className="gap-2"
                >
                  <Upload className="h-4 w-4" />
                  ä¸Šä¼ éŸ³é¢‘
                </Button>
                <Button
                  onClick={startRecording}
                  className="gap-2"
                >
                  <Mic className="h-4 w-4" />
                  å¼€å§‹å½•åˆ¶
                </Button>
              </div>
            </div>
          </div>

          {/* Preset Scenarios */}
          <div className="space-y-3">
            <p className="text-sm text-muted-foreground">é€‰æ‹©ä¸€ä¸ªåœºæ™¯æ¡ˆä¾‹ä½“éªŒè¯­éŸ³åˆæˆ</p>
            <div className="grid grid-cols-2 gap-3">
              {presetScenarios.map((scenario) => (
                <button
                  key={scenario.id}
                  onClick={() => handlePresetClick(scenario)}
                  disabled={isGeneratingPreset !== null}
                  className={`flex items-center gap-3 p-3 rounded-xl border border-border/50 bg-background hover:bg-secondary/50 transition-all text-left ${
                    isGeneratingPreset === scenario.id ? "opacity-70" : ""
                  }`}
                >
                  <div className={`w-10 h-10 rounded-lg ${scenario.bgColor} flex items-center justify-center shrink-0`}>
                    {isGeneratingPreset === scenario.id ? (
                      <Loader2 className={`h-5 w-5 ${scenario.color} animate-spin`} />
                    ) : (
                      <scenario.icon className={`h-5 w-5 ${scenario.color}`} />
                    )}
                  </div>
                  <div className="min-w-0">
                    <div className="flex items-center gap-2">
                      <span className="font-medium text-foreground text-sm">{scenario.title}</span>
                      <span className="text-muted-foreground text-xs">|</span>
                      <span className="text-muted-foreground text-xs truncate">{scenario.subtitle}</span>
                    </div>
                  </div>
                </button>
              ))}
            </div>
          </div>
        </div>
      )}

      {/* Recording State */}
      {isRecording && (
        <div className="bg-primary/5 border border-primary/20 rounded-lg p-6">
          <p className="text-sm text-muted-foreground text-center mb-4">
            è¯·åœ¨å®‰é™ç¯å¢ƒä¸‹æœ—è¯»ä»¥ä¸‹æ–‡æœ¬ï¼Œéœ€å½•åˆ¶10-30ç§’è¯­éŸ³
          </p>
          
          <div className="flex items-center justify-center gap-2 mb-6">
            <p className="text-base text-foreground text-center leading-relaxed max-w-lg">
              {sampleText}
            </p>
            <Button
              variant="ghost"
              size="icon"
              className="h-8 w-8 shrink-0"
              onClick={generateRandomText}
              disabled={isRecording}
            >
              <RefreshCw className="h-4 w-4" />
            </Button>
          </div>

          <div className="flex flex-col items-center gap-4">
            <div className="flex items-center gap-2">
              <div className="flex items-center gap-1">
                {[...Array(20)].map((_, i) => (
                  <div
                    key={i}
                    className="w-1 bg-primary rounded-full animate-pulse"
                    style={{
                      height: `${Math.random() * 20 + 10}px`,
                      animationDelay: `${i * 0.05}s`,
                    }}
                  />
                ))}
              </div>
              <span className="text-sm text-muted-foreground ml-2">ğŸ™ï¸</span>
            </div>
            
            <div className="text-4xl font-bold text-primary">{countdown}S</div>
            <Button
              variant="outline"
              onClick={stopRecording}
              disabled={countdown > 20}
              className="min-w-[120px]"
            >
              ç»“æŸå½•åˆ¶
            </Button>
            {countdown > 20 && (
              <p className="text-xs text-muted-foreground">å½•åˆ¶è‡³å°‘10ç§’åå¯æ‰‹åŠ¨ç»“æŸ</p>
            )}
          </div>
        </div>
      )}

      {/* Delete button fixed at bottom-right, above sentence timeline */}
      {originalAudioUrl && sentences.length > 0 && (
        <div className="fixed bottom-[140px] right-8 z-30">
          <Button
            variant="ghost"
            size="sm"
            className="h-8 text-destructive/60 hover:text-destructive hover:bg-destructive/10 gap-1"
            onClick={deleteAudio}
          >
            <Trash2 className="h-4 w-4" />
            åˆ é™¤
          </Button>
        </div>
      )}

      {/* Upload mode - show simple player */}
      {originalAudioUrl && audioSource === "upload" && (
        <div className="space-y-3">
          <h3 className="text-sm font-medium text-foreground">ä¸Šä¼ çš„éŸ³é¢‘</h3>
          <div className="relative group bg-gradient-to-br from-secondary via-secondary/80 to-secondary rounded-xl p-4 border border-border/50">
            <div className="relative flex items-center justify-between">
              <div className="flex items-center gap-4">
                <div className="flex items-center gap-1 h-8 text-muted-foreground">
                  {Array.from({ length: 15 }, (_, i) => (
                    <div
                      key={i}
                      className="w-0.5 bg-current opacity-40 rounded-full"
                      style={{ height: `${20 + Math.random() * 30}%` }}
                    />
                  ))}
                </div>
                <div>
                  <p className="text-sm font-semibold text-foreground">
                    {originalFileName}
                  </p>
                </div>
              </div>
              
              <Button
                variant="ghost"
                size="icon"
                className="h-8 w-8 text-destructive/60 hover:text-destructive hover:bg-destructive/10"
                onClick={deleteAudio}
              >
                <Trash2 className="h-4 w-4" />
              </Button>
            </div>
          </div>
        </div>
      )}

      {/* Edit Modal */}
      {showModal && createPortal(
        <div className="fixed inset-0 bg-foreground/20 backdrop-blur-sm flex items-center justify-center z-[9999] animate-fade-in">
          <div className="bg-card border border-border rounded-xl p-6 w-full max-w-lg shadow-elevated animate-scale-in mx-4">
            <div className="flex items-center justify-between mb-4">
              <div>
                <h3 className="text-lg font-semibold text-foreground">å‚æ•°è®¾ç½®</h3>
                <p className="text-sm text-muted-foreground">
                  ç¼–è¾‘å¥å­ {editingSentenceId !== null ? editingSentenceId + 1 : ''}
                </p>
              </div>
              <Button
                variant="ghost"
                size="iconSm"
                onClick={() => { setShowModal(false); setSelectedTags([]); setEditingSentenceId(null); }}
              >
                <X className="h-4 w-4" />
              </Button>
            </div>

            {/* Show sentence text being edited */}
            {editingSentenceId !== null && (
              <div className="bg-secondary/50 rounded-lg p-3 mb-4">
                <p className="text-sm text-foreground">
                  {sentences.find(s => s.id === editingSentenceId)?.text}
                </p>
              </div>
            )}

            {/* Tags Section */}
            <div className="space-y-4 mb-6 max-h-[400px] overflow-y-auto pr-2">
              <div>
                <p className="text-sm font-medium text-foreground mb-2">æƒ…ç»ª</p>
                <div className="flex flex-wrap gap-2">
                  {emotionTags.map((tag, i) => (
                    <span
                      key={i}
                      onClick={() => toggleTag(tag)}
                      className={`px-3 py-1 text-xs rounded-full cursor-pointer transition-colors ${
                        selectedTags.includes(tag)
                          ? "bg-primary text-primary-foreground"
                          : "bg-secondary text-secondary-foreground hover:bg-accent hover:text-accent-foreground"
                      }`}
                    >
                      {tag}
                    </span>
                  ))}
                </div>
              </div>

              <div>
                <p className="text-sm font-medium text-foreground mb-2">é£æ ¼</p>
                <div className="flex flex-wrap gap-2">
                  {styleTags.map((tag, i) => (
                    <span
                      key={i}
                      onClick={() => toggleTag(tag)}
                      className={`px-3 py-1 text-xs rounded-full cursor-pointer transition-colors ${
                        selectedTags.includes(tag)
                          ? "bg-primary text-primary-foreground"
                          : "bg-secondary text-secondary-foreground hover:bg-accent hover:text-accent-foreground"
                      }`}
                    >
                      {tag}
                    </span>
                  ))}
                </div>
              </div>

              <div>
                <p className="text-sm font-medium text-foreground mb-2">é€Ÿåº¦æ§åˆ¶</p>
                <div className="flex flex-wrap gap-2">
                  {speedTags.map((tag, i) => (
                    <span
                      key={i}
                      onClick={() => toggleTag(tag)}
                      className={`px-3 py-1 text-xs rounded-full cursor-pointer transition-colors ${
                        selectedTags.includes(tag)
                          ? "bg-primary text-primary-foreground"
                          : "bg-secondary text-secondary-foreground hover:bg-accent hover:text-accent-foreground"
                      }`}
                    >
                      {tag}
                    </span>
                  ))}
                </div>
              </div>
            </div>

            {/* Action Buttons */}
            <div className="flex items-center justify-end gap-3">
              <Button variant="outline" onClick={() => { setShowModal(false); setSelectedTags([]); setEditingSentenceId(null); }}>
                å–æ¶ˆ
              </Button>
              <Button onClick={handleConfirm} disabled={isGenerating}>
                {isGenerating ? (
                  <>
                    <Loader2 className="h-4 w-4 animate-spin mr-2" />
                    ç”Ÿæˆä¸­...
                  </>
                ) : "ç¡®è®¤"}
              </Button>
            </div>
          </div>
        </div>,
        document.body
      )}
    </div>
  );
};

export default VoiceEditTab;
